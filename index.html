<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

	<head>
	    <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-124899665-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
        
          gtag('config', 'UA-124899665-1');
        </script>
		<title>Renjiao Yi at NUDT, 易任娇, 国防科技大学</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />

		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body id="top">
		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/pic-new.jpg" alt="" /></a>
					<h2><strong>Renjiao Yi</strong>（易任娇） <br />Associate Professor <br />National University of Defense Technology<br /></h2>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
						<p>I am an Associate Professor in <a href="http://kevinkaixu.net/group.html">iGrape Group</a> （leading by Professor <a href="http://kevinkaixu.net">Kai Xu</a>, <a href="https://www.nudt.edu.cn/">National University of Defense Technology</a>, China. Before that, I got my PhD in February 2019 in <a href="http://www.sfu.ca/">Simon Fraser University</a>, under the supervision of <a href="https://ece.hkust.edu.hk/pingtan">Prof. Ping Tan</a> in <a href="http://gruvi.cs.sfu.ca/">Gruvi Lab</a>. I got my Bachelor's degree in Computer Science from <a href="http://english.nudt.edu.cn/">National University of Defense Technology</a>, P.R. China. I am interested in 3D vision and graphics, including but not limited to 3D reconstruction, relighitng, inverse rendering etc. </p>
						<p>My homepage was migrated from <a href="http://www.sfu.ca/~renjiaoy/">the old one</a>. 
					</section>
				<!-- Two -->
					<section id="two">
						<h2>News&#128681</h2>
						<div class="row">
							<article class=" 12u$(small) work-item">
								<p><strong>2025-07</strong>,  one paper is accepted by TOG and will be presented on Siggraph Asia 2025! </p>
								<p><strong>2025-06</strong>,  two papers are accepted by ICCV 2025! </p>
								<p><strong>2025-03</strong>,  two papers are accepted by TCSVT! </p>
								<p><strong>2025-02</strong>,  one paper is accepted by CVPR 2025! </p>
                                                                <p><strong>2025-02</strong>,  two papers are accepted by FCS Journal! </p>

							</article>
					</section>
				<!-- Three -->
					<section id="three">
						<h2>Grants</h2>
						<div class="row">
							<article class=" 12u$(small) work-item">

								<p><strong>Young Elite Scientists Sponsorship Program by CAST, 第九届中国科协青托工程</strong>,  2023-2026.</p>
								<p><strong>Hunan Provincial Science and Technology Department Funding. 湖湘青年英才</strong>,  2022-2025.</p>
								<p><strong>National Natural Science Foundation of China. 国家自然科学基金青年项目</strong>,  2021-2023.</p>
								<p><strong>Natural Science Foundation of Hunan Province. 湖南省自然科学基金青年项目</strong>,  2021-2023.</p>

							</article>
					</section>

				<!-- Four -->
					<section id="four">
						<h2>Recent Publications</h2>
						<div class="row">
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/vastsd.png" width= 100% alt="VasTSD: Learning 3D Vascular Tree-state Space Diffusion Model for Angiography Synthesis" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Zhifeng Wang+, <strong>Renjiao Yi+ </strong>, Xin Wen, Chenyang Zhu, Kai Xu
								"<strong>VasTSD: Learning 3D Vascular Tree-state Space Diffusion Model for Angiography Synthesis</strong>", CVPR 2025.<br><br></p>
								<h6>Angiography imaging is a medical imaging technique that enhances the visibility of blood vessels within the body by using contrast agents. Angiographic images can effectively assist in the diagnosis of vascular diseases. However, contrast agents may bring extra radiation exposure which is harmful to patients with health risks. To mitigate these concerns, in this paper, we aim to automatically generate angiography from non-angiographic inputs, by leveraging and enhancing the inherent physical properties of vascular structures. Previous methods relying on 2D slice-based angiography synthesis struggle with maintaining continuity in 3D vascular structures...</h6><p><a href="https://arxiv.org/pdf/2503.12758?">Arxiv</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/cadnerf.png" width= 100% alt="CAD-NeRF: learning NeRFs from uncalibrated few-view images by CAD model retrieval" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Xin Wen, Xuening Zhu, <strong>Renjiao Yi* </strong>, Zhifeng Wang, Chenyang Zhu & Kai Xu*, 
								"<strong>CAD-NeRF: learning NeRFs from uncalibrated few-view images by CAD model retrieval</strong>", Frontiers of Computer Science.<br><br></p>
								<h6>Reconstructing from multi-view images is a longstanding problem in 3D vision, where neural radiance fields (NeRFs) have shown great potential and get realistic rendered images of novel views. Currently, most NeRF methods either require accurate camera poses or a large number of input images, or even both. Reconstructing NeRF from few-view images without poses is challenging and highly ill-posed. To address this problem, we...</h6><p><a href="https://link.springer.com/article/10.1007/s11704-024-40417-7">Link</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/poseprobe.png" width= 100% alt="Generic objects as pose probes for few-shot view synthesis" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Zhirui Gao+, <strong>Renjiao Yi+ </strong>, Chenyang Zhu, Ke Zhuang, Wei Chen, Kai Xu
								"<strong>Generic objects as pose probes for few-shot view synthesis</strong>", IEEE Transactions on Circuits and Systems for Video Technology.<br><br></p>
								<h6>Radiance fields, including NeRFs and 3D Gaussians, demonstrate great potential in high-fidelity rendering and scene reconstruction, while they require a substantial number of posed images as input. COLMAP is frequently employed for preprocessing to estimate poses. However, COLMAP necessitates a large number of feature matches to operate effectively, and struggles with scenes characterized by sparse features, large baselines, or few-view images. We aim to...</h6><p><a href="https://arxiv.org/pdf/2408.16690">Arxiv</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/insertion.png" width= 100% alt="Relighting scenes with object insertions in neural radiance fields" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Xuening Zhu+, <strong>Renjiao Yi+ </strong>, Xin Wen, Chenyang Zhu, Kai Xu
								"<strong>Relighting scenes with object insertions in neural radiance fields</strong>", IEEE Transactions on Circuits and Systems for Video Technology.<br><br></p>
								<h6>Inserting objects into scenes and performing realistic relighting are common applications in augmented reality (AR). Previous methods focused on inserting virtual objects using CAD models or real objects from single-view images, resulting in highly limited AR application scenarios. We introduce a novel pipeline based on Neural Radiance Fields (NeRFs) for seamlessly integrating...</h6><p><a href="https://arxiv.org/pdf/2406.14806">Arxiv</a></p>
							</article>
							<!-- -->
			
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/diffedge.png" width= 100% alt="DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yunfan Ye, Kai Xu, Yuhang Huang, <strong>Renjiao Yi </strong>, Zhiping Cai, 
								"<strong>DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection</strong>", AAAI 2024.<br><br></p>
								<h6>Limited by the encoder-decoder architecture, learning-based edge detectors usually have difficulty predicting edge maps that satisfy both correctness and crispness. With the recent success of the diffusion probabilistic model (DPM), we found...</h6><p><a href="https://arxiv.org/pdf/2401.02032.pdf">Arxiv</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/EFECL.png" width= 100% alt="EFECL: Feature encoding enhancement with contrastive learning for indoor 3D object detection" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yao Duan, <strong>Renjiao Yi </strong>,Yuanming Gao, Kai Xu, Chenyang Zhu,  
								"<strong>EFECL: Feature encoding enhancement with contrastive learning for indoor 3D object detection</strong>", Computational Visual Media (CVMJ).<br><br></p>
								<h6> Good proposal initials are critical for 3D object detection applications. However, due to the significant geometry variation of indoor scenes, incomplete and noisy proposals are inevitable in most cases. Mining feature informatio...</h6><p><a href="https://link.springer.com/content/pdf/10.1007/s41095-023-0366-0.pdf">pdf</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/2d3dmatr.png" width= 100% alt="2D3D-MATR: 2D-3D Matching Transformer for Detection-free Registration between Images and Point Clouds" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Minhao Li, Zheng Qin, Zhirui Gao, <strong>Renjiao Yi</strong>, Chenyang Zhu, Yulan Guo, Kai Xu, 
								"<strong>2D3D-MATR: 2D-3D Matching Transformer for Detection-free Registration between Images and Point Clouds</strong>", ICCV 2023.<br><br></p>
								<h6>The commonly adopted detect-then-match approach to registration finds difficulties in the cross-modality cases due to the incompatible keypoint detection and inconsistent feature description. We propose, 2D3D-MATR, a detectionfree method for...</h6><p><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.pdf">pdf</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/stedge.png" width= 100% alt="STEdge: Self-training Edge Detection with Multi-layer Teaching and Regularization" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yunfan Ye, <strong>Renjiao Yi (co-first author)</strong>, Zhiping Cai, Kai Xu, 
								"<strong>STEdge: Self-training Edge Detection with Multi-layer Teaching and Regularization</strong>", IEEE Transactions on Neural Networks and Learning Systems (TNNLS).<br><br></p>
								<h6>Learning-based edge detection has hereunto been strongly supervised with pixel-wise annotations which are tedious to obtain manually. We study the problem of self-training edge detection, leveraging the untapped wealth of large-scale unlabeled image datasets. We design a self-supervised framework with multi-layer regularization and self-teaching...</h6><p><a href="https://arxiv.org/pdf/2201.05121.pdf">Arxiv (with supplementary material)</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/crispness.png" width= 100% alt="Delving into Crispness: Guided Label Refinement for Crisp Edge Detection" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yunfan Ye, <strong>Renjiao Yi</strong>, Zhirui Gao, Zhiping Cai, Kai Xu,
								"<strong>Delving into Crispness: Guided Label Refinement for Crisp Edge Detection</strong>",  IEEE Transactions on Image Processing.<br><br></p>
								<h6>Learning-based edge detection usually suffers from predicting thick edges. Through extensive quantitative study with a new edge crispness measure, we find that noisy human-labeled edges are the main cause of thick predictions. Based on this observation, we advocate that more attention should be paid on label quality than on model design to achieve crisp edge detection. To this end, we propose an effective ...</h6><p><a href="https://arxiv.org/pdf/2306.15172.pdf">PDF</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/tensorformer.png" width= 100% alt="Tensorformer: Normalized Matrix Attention Transformer for High-quality Point Cloud Reconstruction" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Hui Tian, Zheng Qin, <strong>Renjiao Yi</strong>, Chenyang Zhu, Kai Xu,
								"<strong>Tensorformer: Normalized Matrix Attention Transformer for High-quality Point Cloud Reconstruction</strong>", IEEE Transactions on Multimedia.<br><br></p>
								<h6>Surface reconstruction from raw point clouds has been studied for decades in the computer graphics community, which is highly demanded by modeling and rendering applications nowadays. Classic solutions, such as Poisson surface reconstruction, require point normals as extra input to perform reasonable results. Modern transformer-based methods can work without normals, while the results are less fine-grained due to limited encoding performance in local fusion from discrete points. We introduce ...</h6><p><a href="https://arxiv.org/pdf/2306.15989.pdf">PDF</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/relighting.png" width= 100% alt="Self-supervised Non-Lambertian Single-view Image Relighting" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p><strong>Renjiao Yi*</strong>, Chenyang Zhu*, Kai Xu,
								"<strong>Self-supervised Non-Lambertian Single-view Image Relighting</strong>",  CVPR 2023 (*Co-first authors).<br><br></p>
								<h6>We present a learning-based approach to relighting a single image of non-Lambertian objects. Our method enables inserting objects from photographs into new scenes and relighting them under the new environment lighting, which is essential for AR applications. To relight the object, we solve both inverse rendering and re-rendering. To resolve the ill-posed inverse rendering, we propose a self-supervised method by ...</h6><p><a href="https://arxiv.org/abs/2303.13852">PDF</a>&nbsp&nbsp&nbsp<a href="https://renjiaoyi.github.io/relighting/">Project Page</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/nef.png" width= 100% alt="NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-view Images" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yunfan Ye, <strong>Renjiao Yi</strong>, Zhirui Gao, Chenyang Zhu, Zhiping Cai, Kai Xu,
								"<strong>NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-view Images</strong>",  CVPR 2023.<br><br></p>
								<h6>We study the problem of reconstructing 3D feature curves of an object from a set of calibrated multi-view images. To do so, we learn a neural implicit field representing the density distribution of 3D edges which we refer to as Neural Edge Field (NEF). Inspired by NeRF, NEF is optimized with a view-based rendering loss where a 2D edge map is rendered at a given view and is compared to the ground-truth edge map extracted from the image of that view ...</h6><p><a href="https://arxiv.org/abs/2303.07653">PDF</a>&nbsp&nbsp&nbsp<a href="https://yunfan1202.github.io/NEF/">Project Page</a></p>
							</article>
							<!-- -->
							
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/aaai2023-teaser.JPG" width= 100% alt="Multi-resolution Monocular Depth Map Fusion by Self-supervised Gradient-based Composition" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yaqiao Dai*, <strong>Renjiao Yi*</strong>, Chenyang Zhu, Hongjun He, Kai Xu,
								"<strong>Multi-resolution Monocular Depth Map Fusion by Self-supervised Gradient-based Composition</strong>",  AAAI 2023 Oral presentation (*Co-first authors).<br><br></p>
								<h6>Monocular depth estimation is a challenging problem on which deep neural networks have demonstrated great potential. However, depth maps predicted by existing deep models usually lack fine-grained details due to the convolution operations and the down-samplings in networks. We find that increasing input resolution is helpful to preserve more local details while the estimation at low resolution is more accurate globally. Therefore, we propose a novel depth map fusion module to combine the advantages of estimations with multi-resolution inputs...</h6><p><a href="https://arxiv.org/pdf/2212.01538.pdf">PDF</a>&nbsp&nbsp&nbsp<a href="https://github.com/yuinsky/gradient-based-depth-map-fusion">Codes</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/template.JPG" width= 100% alt="Learning Accurate Template Matching with Differentiable Coarse-to-fine Correspondence Refinement" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Zhirui Gao, <strong>Renjiao Yi</strong>, Zheng Qin, Yunfan Ye, Chenyang Zhu, Kai Xu,
								"<strong>Learning Accurate Template Matching with Differentiable Coarse-to-fine Correspondence Refinement</strong>",  Computational Visual Media (CVMJ).<br><br></p>
								<h6>Template matching is a fundamental task in computer vision and has been studied for decades. It plays an essential role in the manufacturing industry for estimating the poses of different parts, facilitating downstream tasks such as robotic grasping. Existing works fail when the template and source images are in different modalities, cluttered backgrounds or weak textures...</h6><p><a href="template.pdf">PDF</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/6dof.JPG" width= 100% alt="6DOF Pose Estimation of a 3D Rigid Object based on Edge-enhanced Point Pair Features" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Chenyi Liu, Fei Chen, Lu Deng, <strong>Renjiao Yi</strong>, Lintao Zheng, Chenyang Zhu, Jia Wang, Kai Xu,
								"<strong>6DOF Pose Estimation of a 3D Rigid Object based on Edge-enhanced Point Pair Features</strong>", Computational Visual Media (CVMJ).<br><br></p>
								<h6>The point pair feature (PPF) is widely used for 6D pose estimation. In this paper, we propose an efficient 6D pose estimation method based on the PPF framework...</h6><p><a href="https://arxiv.org/pdf/2209.08266.pdf">PDF</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/thp.JPG" width= 100% alt="THP: Tensor-Field-Driven Hierarchical Path Planning for Autonomous Scene Exploration with Depth Sensors" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yuefeng Xi, Chenyang Zhu, Yao Duan, <strong>Renjiao Yi</strong>, Lintao Zheng, Hongjun He, Kai Xu,
								"<strong>THP: Tensor-Field-Driven Hierarchical Path Planning for Autonomous Scene Exploration with Depth Sensors</strong>",  Computational Visual Media (CVMJ).<br><br></p>
								<h6>It is challenging to automatically explore an unknown 3D environment with a robot only equipped with depth sensors due to the limited field of view. We introduce THP, a tensor field-based framework for efficient environment exploration...</h6><p><a href="thp.pdf">PDF</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/disarm.png" width= 100% alt="DisARM: Displacement Aware Relation Module for 3D Detection" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p>Yao Duan, Chenyang Zhu, Yuqing Lan, <strong>Renjiao Yi</strong>, Xinwang Liu, Kai Xu,
								"<strong>DisARM: Displacement Aware Relation Module for 3D Detection</strong>",  CVPR 2022.<br><br></p>
								<h6>We introduce Displacement Aware Relation Module (DisARM), a novel neural network module for enhancing the performance of 3D object detection in point cloud scenes. The core idea of our method is that contextual information is critical to tell the difference when the instance geometry is incomplete or featureless. We find that relations between proposals provide a good representation to describe the context...</h6><p><a href="https://arxiv.org/pdf/2203.01152v1.pdf">Arxiv</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/multiview.png" width= 100% alt="Leveraging Multi-view Image Sets for Unsupervised Intrinsic Image Decomposition and Highlight Separation" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p><strong>Renjiao Yi</strong>, 
								<a href="http://www.cs.sfu.ca/~pingtan/">Ping Tan</a> and <a href="https://www.microsoft.com/en-us/research/people/stevelin/">Stephen Lin</a>, "<strong>Leveraging Multi-view Image Sets for Unsupervised Intrinsic Image Decomposition and Highlight Separation</strong>",  AAAI 2020.<br><br></p>
								<h6>We present an unsupervised approach for factorizing object appearance into highlight, shading, and albedo layers, trained by multi-view real images. To do so, we construct a multi-view dataset by collecting numerous customer product photos online, which exhibit large illumination variations that make them suitable for training of reflectance separation and can facilitate object-level decomposition...</h6><p><a href="https://arxiv.org/pdf/1911.07262.pdf">Arxiv (with supplementary material)</a>&nbsp&nbsp&nbsp<a href="aaaiposter-v3.pdf">Poster</a>&nbsp&nbsp&nbsp<a href="https://www.dropbox.com/s/awk9fa00xvfeqmf/realspeculardata_masked.zip?dl=0">Specularity separation dataset</a>&nbsp&nbsp&nbsp<a id="demo1" onclick="myFunction1()">Bibtex</a></p><script>function myFunction1() {    document.getElementById("demo1").innerHTML = "<br><B>@inproceedings{yi2020leveraging,<br>title={Leveraging Multi-View Image Sets for Unsupervised Intrinsic Image Decomposition and Highlight Separation},<br>author={Yi, Renjiao and Tan, Ping and Lin, Stephen},<br>booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},<br>volume={34},<br>number={07},<br>pages={12685--12692},<br>year={2020}}</B>";}</script>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/thesis.png" width= 100% alt="Image Layer Separation and Application" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p><strong>Renjiao Yi</strong>, 
								"<strong>Image Layer Separation and Application</strong>",  PhD Thesis.<br><br></p>
								<h6>Image layer separation is an important step for image understanding and facilitates many image processing applications. It aims to separate a single image into multiple image layers, decomposing different components of the image. Image layers are either physics-based layers...</h6><p><a href="http://summit.sfu.ca/item/19143">link</a>&nbsp&nbsp&nbsp<a href="https://www.dropbox.com/scl/fi/wrvwi9oyqzrw80iw6mxeg/etd20099.pdf?rlkey=hk3h778lj8lo2mcyra3yq68oj&dl=0">PDF</a></p>
							</article>
							<!-- -->
						        <article class="6u 10u$(xsmall) work-item">
								<img src="images/teaser-faceslight.png" width= 100% alt="Faces as Lighting Probes via Unsupervised Deep Highlight Extraction" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p><strong>Renjiao Yi</strong>, <a href="http://www.sfu.ca/~cza68/">Chenyang Zhu</a>,  
								<a href="http://www.cs.sfu.ca/~pingtan/">Ping Tan</a> and <a href="https://www.microsoft.com/en-us/research/people/stevelin/">Stephen Lin</a>, "<strong>Faces as Lighting Probes via Unsupervised Deep Highlight Extraction</strong>",  ECCV 2018.<br><br></p>
								<h6>We present a method for estimating detailed scene illumination using human faces in a single image. In contrast to previous works that estimate lighting in terms of low-order basis functions or distant point lights, our technique estimates illumination at a higher precision in the form of a non-parametric environment map...</h6><p><a href="https://arxiv.org/pdf/1803.06340v2.pdf">Arxiv (with supplementary material)</a>&nbsp&nbsp&nbsp<a href="https://www.dropbox.com/s/de0x3ot5v3kaew5/FaceAsLightingProbes.rar?dl=0">Codes</a>&nbsp&nbsp&nbsp<a href="eccvposter-v3.pdf">Poster</a>&nbsp&nbsp&nbsp<a id="demo" onclick="myFunction()">Bibtex</a></p><script>function myFunction() {    document.getElementById("demo").innerHTML = "<br><B>@InProceedings{Yi_2018_ECCV,<br>author = {Yi, Renjiao and Zhu, Chenyang and Tan, Ping and Lin, Stephen},<br>title = {Faces as Lighting Probes via Unsupervised Deep Highlight Extraction},<br>booktitle = {The European Conference on Computer Vision (ECCV)},<br>month = {September},<br>year = {2018}}</B>";}</script>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/teaser_scores.png" width= 100% alt="SCORES: Shape Composition with Recursive Substructure Priors" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p><a href="http://www.sfu.ca/~cza68/">Chenyang Zhu</a>, <a href="http://kevinkaixu.net/">Kai Xu</a>, <a href="https://www.cse.iitb.ac.in/~sidch/">Siddhartha Chaudhuri</a>, <strong>Renjiao Yi</strong> and <a href="https://www.cs.sfu.ca/~haoz/">Hao Zhang</a>, 
								<strong>SCORES: Shape Composition with Recursive Substructure Priors</strong>",  ACM Transactions on Graphics (SIGGRAPH Asia 2018).<br><br></p>
								<h6> We introduce SCORES, a recursive neural network for shape composition. Our network takes as input sets of parts from two or more source 3D shapes and a rough initial placement of the parts. It outputs an optimized part structure for the composed shape, leading to high-quality geometry construction. A unique feature of our composition network is that it is not merely learning how to connect parts. Our goal is to produce a coherent and plausible 3D shape...</h6><p><a href="https://arxiv.org/pdf/1809.05398.pdf">Arxiv</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
								<img src="images/teaser9.png" width= 100% alt="Deformation-Driven Shape Correspondence via Shape Recognition" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p><a href="http://www.sfu.ca/~cza68/">Chenyang Zhu</a>, <strong>Renjiao Yi</strong>, 
								<a href="http://www.sfu.ca/~wpintoli/">Wallace Lira</a>, <a href="http://ialhashim.github.io/index.html">Ibraheem Alhashim</a>, <a href="http://kevinkaixu.net/">Kai Xu</a> and <a href="https://www.cs.sfu.ca/~haoz/">Hao Zhang</a>, "<strong>Deformation-Driven Shape Correspondence via Shape Recognition</strong>",  ACM Transactions on Graphics (SIGGRAPH 2017), 36(4): 51, 2017.<br><br></p>
								<h6>Many approaches to shape comparison and recognition start by establishing a shape correspondence. We "turn the table" and show that quality shape correspondences can be obtained by performing many shape recognition tasks. What is more, the method we develop computes a fine-grained, topology-varying part correspondence between two 3D shapes where the core evaluation mechanism only recognizes shapes globally...</h6><p><a href="papers/zhu_sig17_scsr.pdf">PDF</a></p>
							</article>
							<!-- -->
							<article class="6u 10u$(xsmall) work-item">
									<img src="images/teaser2.png" width= 100% alt="Automatic Fence Segmentation in Videos of Dynamic Scenes" ><br>
							</article>
							<article class="6u$ 12u$(xsmall) work-item">
								<p><strong>Renjiao Yi</strong>, <a href="http://www.juew.org/">Jue Wang</a>, <a href="http://www.cs.sfu.ca/~pingtan/">Ping Tan</a> , "<strong>Automatic Fence Segmentation in Videos of Dynamic Scenes</strong>",  IEEE Conference on Computer Vision and Patten Recognition (CVPR), Las Vegas, USA, Jun. 2016. <br><br></p>
								<h6>We present a fully automatic approach to detect and segment fence-like occluders from a video clip. Unlike previous approaches that usually assume either static scenes or cameras, our method is capable of handling both dynamic scenes and moving cameras... </h6><p><a href="papers/0407.pdf">PDF</a>&nbsp&nbsp&nbsp<a href="cvpr16-poster-rj -new3.pdf">Poster</a></p>
							</article>
							
						</div>
						<ul class="actions">
							<li><a href="http://dblp.uni-trier.de/pers/hd/y/Yi:Renjiao" class="button">More on dblp</a></li>
						</ul>
					</section>

				<!-- Five -->
					<section id="five">
						<h2>Get In Touch</h2>
						<div class="row">
							<div class="6u 12u$(small)">
								<ul class="labeled-icons">
									<li>
										<h3 class="icon fa-home"><span class="label">Address</span></h3>
										College of Computer Science, </br>
										National University of Defense Technology,</br>
										109 Deya Road,</br>
										Changsha, Hunan, China
									</li>
									<li>
										<h3 class="icon fa-envelope-o"><span class="label">Email</span></h3>
										<a href="#">yirenjiao@nudt.edu.cn</a></br>
										<a href="#">jiaojiao0526@gmail.com</a>
									</li>
									<li>
										<h3 class="icon fa-line-chart"><span class="label">Email</span></h3>
										        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
        </script>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>,
        </span>
		<span id="busuanzi_container_site_uv">
 <span id="busuanzi_value_site_uv"></span>
</span>
									</li>
								</ul>
							</div>
							<div class="6u$ 12u$(small)">
								<img src="images/nudt2.png" height="137px" width="335px" alt="#"><br>
								<img src="images/sfu.jpg" height="137px" width="335px" alt="#"><br>
							</div>
						</div>
					</section>
				<!-- Four -->
				<!--
					<section id="four">
						<h2>Elements</h2>

						<section>
							<h4>Text</h4>
							<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
							This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
							This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
							<hr />
							<header>
								<h4>Heading with a Subtitle</h4>
								<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
							</header>
							<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
							<header>
								<h5>Heading with a Subtitle</h5>
								<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
							</header>
							<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
							<hr />
							<h2>Heading Level 2</h2>
							<h3>Heading Level 3</h3>
							<h4>Heading Level 4</h4>
							<h5>Heading Level 5</h5>
							<h6>Heading Level 6</h6>
							<hr />
							<h5>Blockquote</h5>
							<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
							<h5>Preformatted</h5>
							<pre><code>i = 0;

while (!deck.isInOrder()) {
print 'Iteration ' + i;
deck.shuffle();
i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
						</section>

						<section>
							<h4>Lists</h4>
							<div class="row">
								<div class="6u 12u$(xsmall)">
									<h5>Unordered</h5>
									<ul>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Sagittis adipiscing lorem eleifend.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ul>
									<h5>Alternate</h5>
									<ul class="alt">
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Sagittis adipiscing lorem eleifend.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ul>
								</div>
								<div class="6u$ 12u$(xsmall)">
									<h5>Ordered</h5>
									<ol>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Etiam vel felis at lorem sed viverra.</li>
										<li>Felis enim feugiat dolore viverra.</li>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Etiam vel felis at lorem sed viverra.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ol>
									<h5>Icons</h5>
									<ul class="icons">
										<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon fa-github"><span class="label">Github</span></a></li>
										<li><a href="#" class="icon fa-dribbble"><span class="label">Dribbble</span></a></li>
										<li><a href="#" class="icon fa-tumblr"><span class="label">Tumblr</span></a></li>
									</ul>
								</div>
							</div>
							<h5>Actions</h5>
							<ul class="actions">
								<li><a href="#" class="button special">Default</a></li>
								<li><a href="#" class="button">Default</a></li>
							</ul>
							<ul class="actions small">
								<li><a href="#" class="button special small">Small</a></li>
								<li><a href="#" class="button small">Small</a></li>
							</ul>
							<div class="row">
								<div class="6u 12u$(small)">
									<ul class="actions vertical">
										<li><a href="#" class="button special">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</div>
								<div class="6u$ 12u$(small)">
									<ul class="actions vertical small">
										<li><a href="#" class="button special small">Small</a></li>
										<li><a href="#" class="button small">Small</a></li>
									</ul>
								</div>
								<div class="6u 12u$(small)">
									<ul class="actions vertical">
										<li><a href="#" class="button special fit">Default</a></li>
										<li><a href="#" class="button fit">Default</a></li>
									</ul>
								</div>
								<div class="6u$ 12u$(small)">
									<ul class="actions vertical small">
										<li><a href="#" class="button special small fit">Small</a></li>
										<li><a href="#" class="button small fit">Small</a></li>
									</ul>
								</div>
							</div>
						</section>

						<section>
							<h4>Table</h4>
							<h5>Default</h5>
							<div class="table-wrapper">
								<table>
									<thead>
										<tr>
											<th>Name</th>
											<th>Description</th>
											<th>Price</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td>Item One</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Two</td>
											<td>Vis ac commodo adipiscing arcu aliquet.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Three</td>
											<td> Morbi faucibus arcu accumsan lorem.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Four</td>
											<td>Vitae integer tempus condimentum.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Five</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
									</tbody>
									<tfoot>
										<tr>
											<td colspan="2"></td>
											<td>100.00</td>
										</tr>
									</tfoot>
								</table>
							</div>

							<h5>Alternate</h5>
							<div class="table-wrapper">
								<table class="alt">
									<thead>
										<tr>
											<th>Name</th>
											<th>Description</th>
											<th>Price</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td>Item One</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Two</td>
											<td>Vis ac commodo adipiscing arcu aliquet.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Three</td>
											<td> Morbi faucibus arcu accumsan lorem.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Four</td>
											<td>Vitae integer tempus condimentum.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Five</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
									</tbody>
									<tfoot>
										<tr>
											<td colspan="2"></td>
											<td>100.00</td>
										</tr>
									</tfoot>
								</table>
							</div>
						</section>

						<section>
							<h4>Buttons</h4>
							<ul class="actions">
								<li><a href="#" class="button special">Special</a></li>
								<li><a href="#" class="button">Default</a></li>
							</ul>
							<ul class="actions">
								<li><a href="#" class="button big">Big</a></li>
								<li><a href="#" class="button">Default</a></li>
								<li><a href="#" class="button small">Small</a></li>
							</ul>
							<ul class="actions fit">
								<li><a href="#" class="button special fit">Fit</a></li>
								<li><a href="#" class="button fit">Fit</a></li>
							</ul>
							<ul class="actions fit small">
								<li><a href="#" class="button special fit small">Fit + Small</a></li>
								<li><a href="#" class="button fit small">Fit + Small</a></li>
							</ul>
							<ul class="actions">
								<li><a href="#" class="button special icon fa-download">Icon</a></li>
								<li><a href="#" class="button icon fa-download">Icon</a></li>
							</ul>
							<ul class="actions">
								<li><span class="button special disabled">Special</span></li>
								<li><span class="button disabled">Default</span></li>
							</ul>
						</section>

						<section>
							<h4>Form</h4>
							<form method="post" action="#">
								<div class="row uniform 50%">
									<div class="6u 12u$(xsmall)">
										<input type="text" name="demo-name" id="demo-name" value="" placeholder="Name" />
									</div>
									<div class="6u$ 12u$(xsmall)">
										<input type="email" name="demo-email" id="demo-email" value="" placeholder="Email" />
									</div>
									<div class="12u$">
										<div class="select-wrapper">
											<select name="demo-category" id="demo-category">
												<option value="">- Category -</option>
												<option value="1">Manufacturing</option>
												<option value="1">Shipping</option>
												<option value="1">Administration</option>
												<option value="1">Human Resources</option>
											</select>
										</div>
									</div>
									<div class="4u 12u$(small)">
										<input type="radio" id="demo-priority-low" name="demo-priority" checked>
										<label for="demo-priority-low">Low Priority</label>
									</div>
									<div class="4u 12u$(small)">
										<input type="radio" id="demo-priority-normal" name="demo-priority">
										<label for="demo-priority-normal">Normal Priority</label>
									</div>
									<div class="4u$ 12u(small)">
										<input type="radio" id="demo-priority-high" name="demo-priority">
										<label for="demo-priority-high">High Priority</label>
									</div>
									<div class="6u 12u$(small)">
										<input type="checkbox" id="demo-copy" name="demo-copy">
										<label for="demo-copy">Email me a copy of this message</label>
									</div>
									<div class="6u$ 12u$(small)">
										<input type="checkbox" id="demo-human" name="demo-human" checked>
										<label for="demo-human">I am a human and not a robot</label>
									</div>
									<div class="12u$">
										<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
									</div>
									<div class="12u$">
										<ul class="actions">
											<li><input type="submit" value="Send Message" class="special" /></li>
											<li><input type="reset" value="Reset" /></li>
										</ul>
									</div>
								</div>
							</form>
						</section>

						<section>
							<h4>Image</h4>
							<h5>Fit</h5>
							<div class="box alt">
								<div class="row 50% uniform">
									<div class="12u$"><span class="image fit"><img src="images/fulls/05.jpg" alt="" /></span></div>
									<div class="4u"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
									<div class="4u"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
									<div class="4u$"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
									<div class="4u"><span class="image fit"><img src="images/thumbs/04.jpg" alt="" /></span></div>
									<div class="4u"><span class="image fit"><img src="images/thumbs/05.jpg" alt="" /></span></div>
									<div class="4u$"><span class="image fit"><img src="images/thumbs/06.jpg" alt="" /></span></div>
									<div class="4u"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
									<div class="4u"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
									<div class="4u$"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
								</div>
							</div>
							<h5>Left &amp; Right</h5>
							<p><span class="image left"><img src="images/google.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
							<p><span class="image right"><img src="images/google.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
						</section>

					</section>
				-->

			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="#" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="#" class="icon fa-github"><span class="label">Github</span></a></li>
						<li><a href="#" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
